{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HACKANONS COLAB 25GB RAM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alpkabac/parlai-scripts/blob/main/BlenderBot2.0%20Script\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1aa8b3a-af83-4bc9-95a9-5f950589ed5b",
        "id": "WuYHYbfkWkZP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping parlai as it is not installed.\u001b[0m\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h  Building wheel for parlai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docformatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.7 MB/s \n",
            "\u001b[?25hCloning into 'ParlAI_SearchEngine'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 218 (delta 117), reused 156 (delta 70), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (218/218), 363.36 KiB | 4.78 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n",
            "\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h\u001b[?25l\n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 51.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install the latest version of ParlAI from source.\n",
        "# This is important, otherwise using Blenderbot 2.0 will not work.\n",
        "!pip uninstall -q parlai -y \n",
        "!pip install -q  --progress-bar off git+https://github.com/facebookresearch/ParlAI.git \n",
        "\n",
        "# Install fairseq. This is required for Blenderbot 2\n",
        "!pip install -q fairseq\n",
        "\n",
        "# Clone the server and install its requirements\n",
        "!git clone https://github.com/JulesGM/ParlAI_SearchEngine.git\n",
        "!pip install -q  --progress-bar off -r ParlAI_SearchEngine/requirements.txt\n",
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import multiprocess\n",
        "import shlex\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# Using port 8080 doesn't work on Colab\n",
        "HOST = \"0.0.0.0:1111\"\n",
        "# Change the following as neede\n",
        "PATH_TO_SEARCH_SERVER = \"./ParlAI_SearchEngine/search_server.py\"\n",
        "\n",
        "assert os.path.exists(PATH_TO_SEARCH_SERVER), (\n",
        "    f\"Incorrect path {PATH_TO_SEARCH_SERVER}\"\n",
        ")\n",
        "\n",
        "command = [\"python\", \"-u\", shlex.quote(PATH_TO_SEARCH_SERVER), \n",
        "           \"serve\", \"--host\", HOST]\n",
        "command_str = \" \".join(command)\n",
        "p = subprocess.Popen(\n",
        "    command, \n",
        "    stderr=subprocess.STDOUT,\n",
        "    stdout=subprocess.PIPE,\n",
        ")\n",
        "\n",
        "# Wait a bit before the next cell to let a lot of the potential errors happen.\n",
        "time.sleep(1)"
      ],
      "metadata": {
        "id": "5EFbnQEmYxM-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ6R7y3s8X1I",
        "outputId": "d5ce0f2c-9ffb-4150-cd67-de6951eead00"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "usage: __main__.py [-h] [--helpall] [--version] COMMAND ...\n",
            "\n",
            "\u001b[0;31m       _\u001b[0;0m\n",
            "\u001b[0;31m      /\u001b[0;0m\u001b[0;90m\"\u001b[0;0m\u001b[0;93m)\u001b[0;0m\n",
            "\u001b[0;31m     //\u001b[0;0m\u001b[0;93m)\u001b[0;0m\n",
            "\u001b[0;32m  ==\u001b[0;0m\u001b[0;34m/\u001b[0;0m\u001b[0;31m/\u001b[0;0m\u001b[0;93m'\u001b[0;0m\u001b[0;32m===\u001b[0;0m ParlAI\n",
            "\u001b[0;34m   /\u001b[0;0m\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help                        show this help message and exit\n",
            "  --helpall                         List all commands, including advanced ones.\n",
            "  --version                         Prints version info and exit.\n",
            "\n",
            "Commands:\n",
            "  \n",
            "  help (h)                          List the main commands.\n",
            "  helpall                           List all commands, including advanced ones.\n",
            "  build_candidates                  Build the candidate responses for a retrieval model\n",
            "  build_dict                        Build a dictionary.\n",
            "  eval_model (em, eval)             Evaluate a model\n",
            "  convert_to_json                   Convert data to json format\n",
            "  convert_to_parlai                 Dump a task to a standardized format\n",
            "  convo_render                      Render data as HTML\n",
            "  data_stats                        Compute data statistics\n",
            "  detect_offensive                  Check task for offensive language\n",
            "  display_data (dd)                 Display data from a task\n",
            "  display_model (dm)                Display model predictions.\n",
            "  train_model (tm, train)           Train a model\n",
            "  eval_wordstat                     Compute statistics from model predictions\n",
            "  extract_image_feature             Load/extract image features\n",
            "  generate_model_card (gmc)         Evaluate a model\n",
            "  interactive (i)                   Interactive chat with a model on the command line\n",
            "  interactive_web (iweb)            Interactive chat with a model in a web browser\n",
            "  multiprocessing_eval (mp_eval)    Evaluate a model\n",
            "  multiprocessing_train (mp_train)  Train a model\n",
            "  party (parrot)                    Throw a party!\n",
            "  profile_interactive               Interactive chat with a model\n",
            "  profile_train                     cProfile a training run\n",
            "  safe_interactive                  Like interactive, but adds a safety filter\n",
            "  self_chat                         Generate self-chats of a model\n",
            "  token_stats                       Compute tokenized stats.\n",
            "  torchscript\n",
            "  vacuum                            Shrink a model file for release.\n",
            "  verify_data                       Check tasks for common errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m parlai interactive --model-file zoo:blenderbot2/blenderbot2_3B/model --search_server $HOST --outfile log.jsonl --save-format conversations --knowledge-access-method memory_only --debug --print-docs "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzS6WXcZ80gL",
        "outputId": "ba0197ac-ab20-49b3-cf8a-a3dddf6c8cb4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "usage: __main__.py interactive [-h] [--helpall] [-o INIT_OPT]\n",
            "                               [--allow-missing-init-opts ALLOW_MISSING_INIT_OPTS]\n",
            "                               [-t TASK] [-dt DATATYPE] [-bs BATCHSIZE]\n",
            "                               [-dynb {full,batchsort,None}] [-v] [--debug]\n",
            "                               [-dp DATAPATH] [-m MODEL] [-mf MODEL_FILE]\n",
            "                               [-im INIT_MODEL] [-d DISPLAY_EXAMPLES]\n",
            "                               [--display-prettify DISPLAY_PRETTIFY]\n",
            "                               [--display-add-fields DISPLAY_ADD_FIELDS]\n",
            "                               [-it INTERACTIVE_TASK] [--outfile OUTFILE]\n",
            "                               [--save-format {conversations,parlai}]\n",
            "                               [-fixedCands LOCAL_HUMAN_CANDIDATES_FILE]\n",
            "                               [--single-turn SINGLE_TURN]\n",
            "                               [--log-keep-fields LOG_KEEP_FIELDS]\n",
            "                               [-cands {batch,inline,fixed,batch-all-cands}]\n",
            "                               [-ecands {batch,inline,fixed,vocab,batch-all-cands}]\n",
            "                               [-icands {fixed,inline,vocab}]\n",
            "                               [--repeat-blocking-heuristic REPEAT_BLOCKING_HEURISTIC]\n",
            "                               [-fcp FIXED_CANDIDATES_PATH]\n",
            "                               [--fixed-candidate-vecs FIXED_CANDIDATE_VECS]\n",
            "                               [--encode-candidate-vecs ENCODE_CANDIDATE_VECS]\n",
            "                               [--init-model INIT_MODEL]\n",
            "                               [--train-predict TRAIN_PREDICT]\n",
            "                               [--cap-num-predictions CAP_NUM_PREDICTIONS]\n",
            "                               [--ignore-bad-candidates IGNORE_BAD_CANDIDATES]\n",
            "                               [--rank-top-k RANK_TOP_K]\n",
            "                               [--return-cand-scores RETURN_CAND_SCORES]\n",
            "                               [--use-memories USE_MEMORIES]\n",
            "                               [--wrap-memory-encoder WRAP_MEMORY_ENCODER]\n",
            "                               [--memory-attention {cosine,dot,sqrt}]\n",
            "                               [--normalize-sent-emb NORMALIZE_SENT_EMB]\n",
            "                               [--share-encoders SHARE_ENCODERS]\n",
            "                               [--learn-embeddings LEARN_EMBEDDINGS]\n",
            "                               [--data-parallel DATA_PARALLEL]\n",
            "                               [--reduction-type {first,max,mean}]\n",
            "                               [--polyencoder-type {codes,n_first}]\n",
            "                               [--poly-n-codes POLY_N_CODES]\n",
            "                               [--poly-attention-type {basic,sqrt,multihead}]\n",
            "                               [--poly-attention-num-heads POLY_ATTENTION_NUM_HEADS]\n",
            "                               [--codes-attention-type {basic,sqrt,multihead}]\n",
            "                               [--codes-attention-num-heads CODES_ATTENTION_NUM_HEADS]\n",
            "                               [-esz EMBEDDING_SIZE] [-nl N_LAYERS]\n",
            "                               [-hid FFN_SIZE] [--dropout DROPOUT]\n",
            "                               [--attention-dropout ATTENTION_DROPOUT]\n",
            "                               [--relu-dropout RELU_DROPOUT]\n",
            "                               [--n-heads N_HEADS]\n",
            "                               [--learn-positional-embeddings LEARN_POSITIONAL_EMBEDDINGS]\n",
            "                               [--embeddings-scale EMBEDDINGS_SCALE]\n",
            "                               [--n-segments N_SEGMENTS]\n",
            "                               [--variant {xlm,aiayn,prelayernorm,bart}]\n",
            "                               [--activation {gelu,relu}]\n",
            "                               [--output-scaling OUTPUT_SCALING]\n",
            "                               [--share-word-embeddings SHARE_WORD_EMBEDDINGS]\n",
            "                               [-nel N_ENCODER_LAYERS] [-ndl N_DECODER_LAYERS]\n",
            "                               [--model-parallel MODEL_PARALLEL]\n",
            "                               [--checkpoint-activations CHECKPOINT_ACTIVATIONS]\n",
            "                               [--generation-model {transformer/generator,bart,t5}]\n",
            "                               [--query-model {bert,bert_from_parlai_rag,dropout_poly}]\n",
            "                               [--rag-model-type {token,sequence,turn}]\n",
            "                               [--thorough THOROUGH]\n",
            "                               [--n-extra-positions N_EXTRA_POSITIONS]\n",
            "                               [--gold-knowledge-passage-key GOLD_KNOWLEDGE_PASSAGE_KEY]\n",
            "                               [--gold-knowledge-title-key GOLD_KNOWLEDGE_TITLE_KEY]\n",
            "                               [--rag-retriever-query {one_turn,full_history}]\n",
            "                               [--rag-retriever-type {dpr,tfidf,dpr_then_poly,poly_faiss,search_engine,search_term_faiss,observation_echo_retriever}]\n",
            "                               [--retriever-debug-index {None,none,exact,compressed}]\n",
            "                               [--n-docs N_DOCS]\n",
            "                               [--min-doc-token-length MIN_DOC_TOKEN_LENGTH]\n",
            "                               [--max-doc-token-length MAX_DOC_TOKEN_LENGTH]\n",
            "                               [--rag-query-truncate RAG_QUERY_TRUNCATE]\n",
            "                               [--print-docs PRINT_DOCS]\n",
            "                               [--path-to-index PATH_TO_INDEX]\n",
            "                               [--path-to-dense-embeddings PATH_TO_DENSE_EMBEDDINGS]\n",
            "                               [--dpr-model-file DPR_MODEL_FILE]\n",
            "                               [--path-to-dpr-passages PATH_TO_DPR_PASSAGES]\n",
            "                               [--retriever-embedding-size RETRIEVER_EMBEDDING_SIZE]\n",
            "                               [--tfidf-max-doc-paragraphs TFIDF_MAX_DOC_PARAGRAPHS]\n",
            "                               [--tfidf-model-path TFIDF_MODEL_PATH]\n",
            "                               [--dpr-num-docs DPR_NUM_DOCS]\n",
            "                               [--poly-score-initial-lambda POLY_SCORE_INITIAL_LAMBDA]\n",
            "                               [--polyencoder-init-model POLYENCODER_INIT_MODEL]\n",
            "                               [--poly-faiss-model-file POLY_FAISS_MODEL_FILE]\n",
            "                               [--regret REGRET]\n",
            "                               [--regret-intermediate-maxlen REGRET_INTERMEDIATE_MAXLEN]\n",
            "                               [--regret-model-file REGRET_MODEL_FILE]\n",
            "                               [--regret-dict-file REGRET_DICT_FILE]\n",
            "                               [--regret-override-index REGRET_OVERRIDE_INDEX]\n",
            "                               [--indexer-type {exact,compressed}]\n",
            "                               [--indexer-buffer-size INDEXER_BUFFER_SIZE]\n",
            "                               [--compressed-indexer-factory COMPRESSED_INDEXER_FACTORY]\n",
            "                               [--compressed-indexer-nprobe COMPRESSED_INDEXER_NPROBE]\n",
            "                               [--rag-turn-n-turns RAG_TURN_N_TURNS]\n",
            "                               [--rag-turn-marginalize {doc_only,doc_then_turn}]\n",
            "                               [--rag-turn-discount-factor RAG_TURN_DISCOUNT_FACTOR]\n",
            "                               [--beam-size BEAM_SIZE]\n",
            "                               [--beam-min-length BEAM_MIN_LENGTH]\n",
            "                               [--beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM]\n",
            "                               [--beam-block-ngram BEAM_BLOCK_NGRAM]\n",
            "                               [--beam-block-full-context BEAM_BLOCK_FULL_CONTEXT]\n",
            "                               [--beam-length-penalty BEAM_LENGTH_PENALTY]\n",
            "                               [--inference {delayedbeam,topk,nucleus,beam,greedy}]\n",
            "                               [--topk TOPK] [--topp TOPP]\n",
            "                               [--beam-delay BEAM_DELAY]\n",
            "                               [--beam-block-list-filename BEAM_BLOCK_LIST_FILENAME]\n",
            "                               [--temperature TEMPERATURE]\n",
            "                               [--compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU]\n",
            "                               [-i INTERACTIVE_MODE]\n",
            "                               [-emb {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}]\n",
            "                               [-embp EMBEDDING_PROJECTION] [--fp16 FP16]\n",
            "                               [--fp16-impl {safe,mem_efficient}]\n",
            "                               [-opt OPTIMIZER] [-lr LEARNINGRATE]\n",
            "                               [-clip GRADIENT_CLIP]\n",
            "                               [--adafactor-eps ADAFACTOR_EPS] [-mom MOMENTUM]\n",
            "                               [--nesterov NESTEROV] [-nu NUS] [-beta BETAS]\n",
            "                               [-wdecay WEIGHT_DECAY] [-rc RANK_CANDIDATES]\n",
            "                               [-tr TRUNCATE] [--text-truncate TEXT_TRUNCATE]\n",
            "                               [--label-truncate LABEL_TRUNCATE]\n",
            "                               [--history-reversed HISTORY_REVERSED]\n",
            "                               [-histsz HISTORY_SIZE] [-pt PERSON_TOKENS]\n",
            "                               [--split-lines SPLIT_LINES]\n",
            "                               [--delimiter DELIMITER]\n",
            "                               [--special-tok-lst SPECIAL_TOK_LST]\n",
            "                               [-gpu GPU | --no-cuda] [--bpe-vocab BPE_VOCAB]\n",
            "                               [--bpe-merge BPE_MERGE]\n",
            "                               [--bpe-dropout BPE_DROPOUT]\n",
            "                               [--lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}]\n",
            "                               [--lr-scheduler-patience LR_SCHEDULER_PATIENCE]\n",
            "                               [--lr-scheduler-decay LR_SCHEDULER_DECAY]\n",
            "                               [--invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA]\n",
            "                               [--t5-model-arch {t5-small,t5-base,t5-large,t5-3b,t5-11b}]\n",
            "                               [--t5-model-parallel T5_MODEL_PARALLEL]\n",
            "                               [--t5-dropout T5_DROPOUT]\n",
            "                               [--t5-generation-config {summarization,translation_en_to_de,translation_en_to_fr,translation_en_to_ro}]\n",
            "                               [--search-query-generator-model-file SEARCH_QUERY_GENERATOR_MODEL_FILE]\n",
            "                               [--search-query-generator-inference SEARCH_QUERY_GENERATOR_INFERENCE]\n",
            "                               [--search-query-generator-beam-min-length SEARCH_QUERY_GENERATOR_BEAM_MIN_LENGTH]\n",
            "                               [--search-query-generator-beam-size SEARCH_QUERY_GENERATOR_BEAM_SIZE]\n",
            "                               [--search-query-generator-text-truncate SEARCH_QUERY_GENERATOR_TEXT_TRUNCATE]\n",
            "                               [--splitted-chunk-length SPLITTED_CHUNK_LENGTH]\n",
            "                               [--doc-chunk-split-mode {word,token}]\n",
            "                               [--n-ranked-doc-chunks N_RANKED_DOC_CHUNKS]\n",
            "                               [--doc-chunks-ranker {tfidf,head}]\n",
            "                               [--search-server SEARCH_SERVER]\n",
            "                               [--knowledge-access-method {classify,memory_only,search_only,all,none}]\n",
            "                               [--memory-key MEMORY_KEY]\n",
            "                               [--query-generator-key QUERY_GENERATOR_KEY]\n",
            "                               [--gold-document-key GOLD_DOCUMENT_KEY]\n",
            "                               [--gold-sentence-key GOLD_SENTENCE_KEY]\n",
            "                               [--gold-document-titles-key GOLD_DOCUMENT_TITLES_KEY]\n",
            "                               [--insert-gold-docs INSERT_GOLD_DOCS]\n",
            "                               [--memory-extractor-phrase MEMORY_EXTRACTOR_PHRASE]\n",
            "                               [--retriever-ignore-phrase RETRIEVER_IGNORE_PHRASE]\n",
            "                               [--query-generator-ignore-phrase QUERY_GENERATOR_IGNORE_PHRASE]\n",
            "                               [--query-generator-model-file QUERY_GENERATOR_MODEL_FILE]\n",
            "                               [--query-generator-delimiter QUERY_GENERATOR_DELIMITER]\n",
            "                               [--query-generator-inference QUERY_GENERATOR_INFERENCE]\n",
            "                               [--query-generator-beam-size QUERY_GENERATOR_BEAM_SIZE]\n",
            "                               [--query-generator-beam-min-length QUERY_GENERATOR_BEAM_MIN_LENGTH]\n",
            "                               [--query-generator-truncate QUERY_GENERATOR_TRUNCATE]\n",
            "                               [--memory-retriever-truncate MEMORY_RETRIEVER_TRUNCATE]\n",
            "                               [--retriever-delimiter RETRIEVER_DELIMITER]\n",
            "                               [--share-search-and-memory-query-encoder SHARE_SEARCH_AND_MEMORY_QUERY_ENCODER]\n",
            "                               [--memory-reader-model {bert,bert_from_parlai_rag,dropout_poly}]\n",
            "                               [--memory-doc-title-delimiter MEMORY_DOC_TITLE_DELIMITER]\n",
            "                               [--memory-decoder-key MEMORY_DECODER_KEY]\n",
            "                               [--memory-decoder-ignore-phrase MEMORY_DECODER_IGNORE_PHRASE]\n",
            "                               [--memory-decoder-model-file MEMORY_DECODER_MODEL_FILE]\n",
            "                               [--memory-decoder-delimiter MEMORY_DECODER_DELIMITER]\n",
            "                               [--memory-decoder-beam-size MEMORY_DECODER_BEAM_SIZE]\n",
            "                               [--memory-decoder-beam-min-length MEMORY_DECODER_BEAM_MIN_LENGTH]\n",
            "                               [--memory-decoder-truncate MEMORY_DECODER_TRUNCATE]\n",
            "                               [--memory-decoder-one-line-memories MEMORY_DECODER_ONE_LINE_MEMORIES]\n",
            "\n",
            "Interactive chat with a model on the command line\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: interactive)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        train)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {full,batchsort,None}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  --debug\n",
            "        Enables some debug behavior\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n",
            "  -d, --display-examples DISPLAY_EXAMPLES\n",
            "  --display-prettify DISPLAY_PRETTIFY\n",
            "        Set to use a prettytable when displaying examples with text candidates\n",
            "        (default: False)\n",
            "  --display-add-fields DISPLAY_ADD_FIELDS\n",
            "        Display these fields when verbose is off (e.g., \"--display-add-fields\n",
            "        label_candidates,beam_texts\") (default: )\n",
            "  -it, --interactive-task INTERACTIVE_TASK\n",
            "        Create interactive version of task (default: True)\n",
            "  --outfile OUTFILE\n",
            "        Saves a jsonl file containing all of the task examples and model\n",
            "        replies. Set to the empty string to not save at all (default: )\n",
            "  --save-format {conversations,parlai}\n",
            "        Format to save logs in. conversations is a jsonl format, parlai is a\n",
            "        text format. (default: conversations)\n",
            "  -fixedCands, --local-human-candidates-file LOCAL_HUMAN_CANDIDATES_FILE\n",
            "        File of label_candidates to send to other agent (default: None)\n",
            "  --single-turn SINGLE_TURN\n",
            "        If on, assumes single turn episodes. (default: False)\n",
            "  --log-keep-fields LOG_KEEP_FIELDS\n",
            "        Fields to keep when logging. Should be a comma separated list\n",
            "        (default: all)\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "        show this help message and exit\n",
            "  --helpall\n",
            "        Show usage, including advanced arguments.\n",
            "  -d, --display-examples DISPLAY_EXAMPLES\n",
            "  --display-prettify DISPLAY_PRETTIFY\n",
            "        Set to use a prettytable when displaying examples with text candidates\n",
            "        (default: False)\n",
            "  --display-add-fields DISPLAY_ADD_FIELDS\n",
            "        Display these fields when verbose is off (e.g., \"--display-add-fields\n",
            "        label_candidates,beam_texts\") (default: )\n",
            "  -it, --interactive-task INTERACTIVE_TASK\n",
            "        Create interactive version of task (default: True)\n",
            "  --outfile OUTFILE\n",
            "        Saves a jsonl file containing all of the task examples and model\n",
            "        replies. Set to the empty string to not save at all (default: )\n",
            "  --save-format {conversations,parlai}\n",
            "        Format to save logs in. conversations is a jsonl format, parlai is a\n",
            "        text format. (default: conversations)\n",
            "\n",
            "Main ParlAI Arguments:\n",
            "  -o, --init-opt INIT_OPT\n",
            "        Path to json file of options. Note: Further Command-line arguments\n",
            "        override file-based options. (default: None)\n",
            "  --allow-missing-init-opts ALLOW_MISSING_INIT_OPTS\n",
            "        Warn instead of raising if an argument passed in with --init-opt is\n",
            "        not in the target opt. (default: False)\n",
            "  -t, --task TASK\n",
            "        ParlAI task(s), e.g. \"babi:Task1\" or \"babi,cbt\" (default: interactive)\n",
            "  -dt, --datatype DATATYPE\n",
            "        choose from: train, train:ordered, valid, test. to stream data add\n",
            "        \":stream\" to any option (e.g., train:stream). by default train is\n",
            "        random with replacement, valid is ordered, test is ordered. (default:\n",
            "        train)\n",
            "  -bs, --batchsize BATCHSIZE\n",
            "        batch size for minibatch training schemes (default: 1)\n",
            "  -dynb, --dynamic-batching {full,batchsort,None}\n",
            "        Use dynamic batching (default: None)\n",
            "  -v, --verbose\n",
            "        Print all messages\n",
            "  --debug\n",
            "        Enables some debug behavior\n",
            "  -dp, --datapath DATAPATH\n",
            "        path to datasets, defaults to {parlai_dir}/data (default: None)\n",
            "\n",
            "ParlAI Model Arguments:\n",
            "  -m, --model MODEL\n",
            "        the model class name. can match parlai/agents/<model> for agents in\n",
            "        that directory, or can provide a fully specified module for `from X\n",
            "        import Y` via `-m X:Y` (e.g. `-m\n",
            "        parlai.agents.seq2seq.seq2seq:Seq2SeqAgent`) (default: None)\n",
            "  -mf, --model-file MODEL_FILE\n",
            "        model file name for loading and saving models (default: None)\n",
            "  -im INIT_MODEL\n",
            "        Initialize model weights and dict from this file (default: None)\n",
            "\n",
            "Local Human Arguments:\n",
            "  -fixedCands, --local-human-candidates-file LOCAL_HUMAN_CANDIDATES_FILE\n",
            "        File of label_candidates to send to other agent (default: None)\n",
            "  --single-turn SINGLE_TURN\n",
            "        If on, assumes single turn episodes. (default: False)\n",
            "\n",
            "World Logging:\n",
            "  --log-keep-fields LOG_KEEP_FIELDS\n",
            "        Fields to keep when logging. Should be a comma separated list\n",
            "        (default: all)\n",
            "\n",
            "TorchRankerAgent:\n",
            "  -cands, --candidates {batch,inline,fixed,batch-all-cands}\n",
            "        The source of candidates during training (see\n",
            "        TorchRankerAgent._build_candidates() for details). (default: inline)\n",
            "  -ecands, --eval-candidates {batch,inline,fixed,vocab,batch-all-cands}\n",
            "        The source of candidates during evaluation (defaults to the samevalue\n",
            "        as --candidates if no flag is given) (default: inline)\n",
            "  -icands, --interactive-candidates {fixed,inline,vocab}\n",
            "        The source of candidates during interactive mode. Since in interactive\n",
            "        mode, batchsize == 1, we cannot use batch candidates. (default: fixed)\n",
            "  --repeat-blocking-heuristic REPEAT_BLOCKING_HEURISTIC\n",
            "        Block repeating previous utterances. Helpful for many models that\n",
            "        score repeats highly, so switched on by default. (default: True)\n",
            "  -fcp, --fixed-candidates-path FIXED_CANDIDATES_PATH\n",
            "        A text file of fixed candidates to use for all examples, one candidate\n",
            "        per line (default: None)\n",
            "  --fixed-candidate-vecs FIXED_CANDIDATE_VECS\n",
            "        One of \"reuse\", \"replace\", or a path to a file with vectors\n",
            "        corresponding to the candidates at --fixed-candidates-path. The\n",
            "        default path is a /path/to/model-file.<cands_name>, where <cands_name>\n",
            "        is the name of the file (not the full path) passed by the flag\n",
            "        --fixed-candidates-path. By default, this file is created once and\n",
            "        reused. To replace it, use the \"replace\" option. (default: reuse)\n",
            "  --encode-candidate-vecs ENCODE_CANDIDATE_VECS\n",
            "        Cache and save the encoding of the candidate vecs. This might be used\n",
            "        when interacting with the model in real time or evaluating on fixed\n",
            "        candidate set when the encoding of the candidates is independent of\n",
            "        the input. (default: True)\n",
            "  --init-model INIT_MODEL\n",
            "        Initialize model with weights from this file. (default: None)\n",
            "  --train-predict TRAIN_PREDICT\n",
            "        Get predictions and calculate mean rank during the train step. Turning\n",
            "        this on may slow down training. (default: False)\n",
            "  --cap-num-predictions CAP_NUM_PREDICTIONS\n",
            "        Limit to the number of predictions in output.text_candidates (default:\n",
            "        100)\n",
            "  --ignore-bad-candidates IGNORE_BAD_CANDIDATES\n",
            "        Ignore examples for which the label is not present in the label\n",
            "        candidates. Default behavior results in RuntimeError. (default: False)\n",
            "  --rank-top-k RANK_TOP_K\n",
            "        Ranking returns the top k results of k > 0, otherwise sorts every\n",
            "        single candidate according to the ranking. (default: -1)\n",
            "  --return-cand-scores RETURN_CAND_SCORES\n",
            "        Return sorted candidate scores from eval_step (default: False)\n",
            "\n",
            "Transformer Arguments:\n",
            "  --use-memories USE_MEMORIES\n",
            "        use memories: must implement the function `_vectorize_memories` to use\n",
            "        this (default: False)\n",
            "  --wrap-memory-encoder WRAP_MEMORY_ENCODER\n",
            "        wrap memory encoder with MLP (default: False)\n",
            "  --memory-attention {cosine,dot,sqrt}\n",
            "        similarity for basic attention mechanism when using transformer to\n",
            "        encode memories (default: sqrt)\n",
            "  --normalize-sent-emb NORMALIZE_SENT_EMB\n",
            "  --share-encoders SHARE_ENCODERS\n",
            "  --learn-embeddings LEARN_EMBEDDINGS\n",
            "        learn embeddings (default: True)\n",
            "  --data-parallel DATA_PARALLEL\n",
            "        use model in data parallel, requires multiple gpus (default: False)\n",
            "  --reduction-type {first,max,mean}\n",
            "        Type of reduction at the end of transformer (default: mean)\n",
            "\n",
            "Polyencoder Arguments:\n",
            "  --polyencoder-type {codes,n_first}\n",
            "        Type of polyencoder, either we computevectors using codes + attention,\n",
            "        or we simply take the first N vectors. (default: codes)\n",
            "  --poly-n-codes POLY_N_CODES\n",
            "        number of vectors used to represent the contextin the case of n_first,\n",
            "        those are the numberof vectors that are considered. (default: 64)\n",
            "  --poly-attention-type {basic,sqrt,multihead}\n",
            "        Type of the top aggregation layer of the poly-encoder (where the\n",
            "        candidate representation isthe key) (default: basic)\n",
            "  --poly-attention-num-heads POLY_ATTENTION_NUM_HEADS\n",
            "        In case poly-attention-type is multihead, specify the number of heads\n",
            "        (default: 4)\n",
            "  --codes-attention-type {basic,sqrt,multihead}\n",
            "        Type (default: basic)\n",
            "  --codes-attention-num-heads CODES_ATTENTION_NUM_HEADS\n",
            "        In case codes-attention-type is multihead, specify the number of heads\n",
            "        (default: 4)\n",
            "\n",
            "Transformer Arguments:\n",
            "  -esz, --embedding-size EMBEDDING_SIZE\n",
            "        Size of all embedding layers. Must be a multiple of --n-heads.\n",
            "        (default: 300)\n",
            "  -nl, --n-layers N_LAYERS\n",
            "        Number of transformer layers. (default: 2)\n",
            "  -hid, --ffn-size FFN_SIZE\n",
            "        Hidden size of the FFN layers (default: 300)\n",
            "  --dropout DROPOUT\n",
            "        Dropout used around embeddings and before layer layer normalizations.\n",
            "        This is used in Vaswani 2017 and works well on large datasets.\n",
            "        (default: 0.0)\n",
            "  --attention-dropout ATTENTION_DROPOUT\n",
            "        Dropout used after attention softmax. This is not used in Vaswani\n",
            "        2017. (default: 0.0)\n",
            "  --relu-dropout RELU_DROPOUT\n",
            "        Dropout used after the ReLU in the FFN. Not used in Vaswani 2017, but\n",
            "        used in Tensor2Tensor. (default: 0.0)\n",
            "  --n-heads N_HEADS\n",
            "        Number of multihead attention heads (default: 2)\n",
            "  --learn-positional-embeddings LEARN_POSITIONAL_EMBEDDINGS\n",
            "        If off, sinusoidal embeddings are used. If on, position embeddings are\n",
            "        learned from scratch. (default: False)\n",
            "  --embeddings-scale EMBEDDINGS_SCALE\n",
            "  --n-segments N_SEGMENTS\n",
            "        The number of segments that support the model. If zero no segment and\n",
            "        no langs_embedding. (default: 0)\n",
            "  --variant {xlm,aiayn,prelayernorm,bart}\n",
            "        Chooses locations of layer norms, etc. prelayernorm is used to match\n",
            "        some fairseq models (default: aiayn, recommended: xlm)\n",
            "  --activation {gelu,relu}\n",
            "        Nonlinear activation to use. AIAYN uses relu, but more recent papers\n",
            "        prefer gelu. (default: relu, recommended: gelu)\n",
            "  --output-scaling OUTPUT_SCALING\n",
            "        scale the output of every transformer by this quantity. (default: 1.0)\n",
            "  --share-word-embeddings SHARE_WORD_EMBEDDINGS\n",
            "        Share word embeddings table for candidate and contextin the memory\n",
            "        network (default: True)\n",
            "  -nel, --n-encoder-layers N_ENCODER_LAYERS\n",
            "        This will overidde the n-layers for asymmetrical transformers\n",
            "        (default: -1)\n",
            "  -ndl, --n-decoder-layers N_DECODER_LAYERS\n",
            "        This will overidde the n-layers for asymmetrical transformers\n",
            "        (default: -1)\n",
            "  --model-parallel MODEL_PARALLEL\n",
            "        Shard the layers across multiple GPUs. (default: False)\n",
            "  --checkpoint-activations CHECKPOINT_ACTIVATIONS\n",
            "        Recompute activations on backward pass to conserve memory. (default:\n",
            "        False)\n",
            "\n",
            "RAG Model Args:\n",
            "  --generation-model {transformer/generator,bart,t5}\n",
            "        which generation model to use (default: bart)\n",
            "  --query-model {bert,bert_from_parlai_rag,dropout_poly}\n",
            "        Which query model to use for DPR. (default: bert)\n",
            "  --rag-model-type {token,sequence,turn}\n",
            "        which rag model decoding to use. (default: token)\n",
            "  --thorough THOROUGH\n",
            "        whether to use thorough decoding for rag sequence. (default: False)\n",
            "\n",
            "Modified RAG Args:\n",
            "  --n-extra-positions N_EXTRA_POSITIONS\n",
            "        Specify > 0 to include extra positions in the encoder, in which\n",
            "        retrieved knowledge will go. In this setup, knowledge is _appended_\n",
            "        instead of prepended. (default: 0)\n",
            "  --gold-knowledge-passage-key GOLD_KNOWLEDGE_PASSAGE_KEY\n",
            "        key in the observation dict that indicates the gold knowledge passage.\n",
            "        Specify, along with --debug, to compute passage retrieval metrics at\n",
            "        train/test time. (default: checked_sentence)\n",
            "  --gold-knowledge-title-key GOLD_KNOWLEDGE_TITLE_KEY\n",
            "        key in the observation dict that indicates the gold knowledge passage\n",
            "        title. Specify, along with --debug, to compute passage retrieval\n",
            "        metrics at train/test time. (default: title)\n",
            "\n",
            "RAG Retriever Args:\n",
            "  --rag-retriever-query {one_turn,full_history}\n",
            "        What to use as the query for retrieval. `one_turn` retrieves only on\n",
            "        the last turn of dialogue; `full_history` retrieves based on the full\n",
            "        dialogue history. (default: full_history)\n",
            "  --rag-retriever-type {dpr,tfidf,dpr_then_poly,poly_faiss,search_engine,search_term_faiss,observation_echo_retriever}\n",
            "        Which retriever to use (default: dpr)\n",
            "  --retriever-debug-index {None,none,exact,compressed}\n",
            "        Load specified small index, for debugging. (default: None)\n",
            "  --n-docs N_DOCS\n",
            "        How many documents to retrieve (default: 5)\n",
            "  --min-doc-token-length MIN_DOC_TOKEN_LENGTH\n",
            "        minimum amount of information to retain from document. Useful to\n",
            "        define if encoder does not use a lot of BPE token context. (default:\n",
            "        64)\n",
            "  --max-doc-token-length MAX_DOC_TOKEN_LENGTH\n",
            "        maximum amount of information to retain from document. (default: 256)\n",
            "  --rag-query-truncate RAG_QUERY_TRUNCATE\n",
            "        Max token length of query for retrieval. (default: 512)\n",
            "  --print-docs PRINT_DOCS\n",
            "        Whether to print docs; usually useful during interactive mode.\n",
            "        (default: False)\n",
            "\n",
            "RAG Dense Passage Retriever Args:\n",
            "  --path-to-index PATH_TO_INDEX\n",
            "        path to FAISS Index. (default:\n",
            "        zoo:hallucination/wiki_index_compressed/compressed_pq)\n",
            "  --path-to-dense-embeddings PATH_TO_DENSE_EMBEDDINGS\n",
            "        path to dense embeddings directory used to build index. Default None\n",
            "        will assume embeddings and index are in the same directory. (default:\n",
            "        None)\n",
            "  --dpr-model-file DPR_MODEL_FILE\n",
            "        path to DPR Model. (default:\n",
            "        zoo:hallucination/multiset_dpr/hf_bert_base.cp)\n",
            "  --path-to-dpr-passages PATH_TO_DPR_PASSAGES\n",
            "        Path to DPR passages, used to build index. (default:\n",
            "        zoo:hallucination/wiki_passages/psgs_w100.tsv)\n",
            "  --retriever-embedding-size RETRIEVER_EMBEDDING_SIZE\n",
            "        Embedding size of dense retriever (default: 768)\n",
            "\n",
            "RAG TFIDF Retriever Args:\n",
            "  --tfidf-max-doc-paragraphs TFIDF_MAX_DOC_PARAGRAPHS\n",
            "        If > 0, limit documents to this many paragraphs (default: -1)\n",
            "  --tfidf-model-path TFIDF_MODEL_PATH\n",
            "        Optionally override TFIDF model. (default:\n",
            "        zoo:wikipedia_full/tfidf_retriever/model)\n",
            "\n",
            "RAG DPR-POLY Retriever Args:\n",
            "  --dpr-num-docs DPR_NUM_DOCS\n",
            "        In two stage retrieval, how many DPR documents to retrieve (default:\n",
            "        25)\n",
            "  --poly-score-initial-lambda POLY_SCORE_INITIAL_LAMBDA\n",
            "        In two stage retrieval, how much weight to give to the poly scores.\n",
            "        Note: Learned parameter. Specify initial value here (default: 0.5)\n",
            "  --polyencoder-init-model POLYENCODER_INIT_MODEL\n",
            "        Which init model to initialize polyencoder with. Specify wikito or\n",
            "        reddit to use models from the ParlAI zoo; otherwise, provide a path to\n",
            "        a trained polyencoder (default: wikito)\n",
            "\n",
            "RAG PolyFAISS retriever args:\n",
            "  --poly-faiss-model-file POLY_FAISS_MODEL_FILE\n",
            "        path to poly-encoder for use in poly-faiss retrieval. (default: None)\n",
            "\n",
            "RAG ReGReT args:\n",
            "  --regret REGRET\n",
            "        Retrieve, Generate, Retrieve, Tune. Retrieve, generate, then retrieve\n",
            "        again, and finally tune (refine). (default: False)\n",
            "  --regret-intermediate-maxlen REGRET_INTERMEDIATE_MAXLEN\n",
            "        Maximum length in intermediate regret generation (default: 32)\n",
            "  --regret-model-file REGRET_MODEL_FILE\n",
            "        Path to model for initial round of retrieval. (default: None)\n",
            "  --regret-dict-file REGRET_DICT_FILE\n",
            "        Path to dict file for model for initial round of retrieval. (default:\n",
            "        None)\n",
            "  --regret-override-index REGRET_OVERRIDE_INDEX\n",
            "        Overrides the index used with the ReGReT model, if using separate\n",
            "        models. I.e., the initial round of retrieval uses the same index as\n",
            "        specified for the second round of retrieval (default: False)\n",
            "\n",
            "RAG Indexer Args:\n",
            "  --indexer-type {exact,compressed}\n",
            "        Granularity of RAG Indexer. Choose compressed to save on RAM costs, at\n",
            "        the possible expense of accuracy. (default: compressed)\n",
            "  --indexer-buffer-size INDEXER_BUFFER_SIZE\n",
            "        buffer size for adding vectors to the index (default: 65536)\n",
            "  --compressed-indexer-factory COMPRESSED_INDEXER_FACTORY\n",
            "        If specified, builds compressed indexer from a FAISS Index Factory.\n",
            "        see https://github.com/facebookresearch/faiss/wiki/The-index-factory\n",
            "        for details (default: IVF4096_HNSW128,PQ128)\n",
            "  --compressed-indexer-nprobe COMPRESSED_INDEXER_NPROBE\n",
            "        How many centroids to search in compressed indexer. See\n",
            "        https://github.com/facebookresearch/faiss/wiki/Faiss-indexes#cell-\n",
            "        probe-methods-indexivf-indexes for details (default: 64)\n",
            "\n",
            "RAG-Turn Args:\n",
            "  --rag-turn-n-turns RAG_TURN_N_TURNS\n",
            "        how many turns to split up retrieval into. The most recent text is\n",
            "        split by delimiter; all turns after (n-1)th turn are combined.\n",
            "        (default: 2)\n",
            "  --rag-turn-marginalize {doc_only,doc_then_turn}\n",
            "        how to marginalize rag-turn. (default: doc_then_turn)\n",
            "  --rag-turn-discount-factor RAG_TURN_DISCOUNT_FACTOR\n",
            "        discount factor for turns beyond most recent one. We employ\n",
            "        exponential discounting. Only considered if 0 < factor < 1.0.\n",
            "        (default: 1.0)\n",
            "\n",
            "Torch Generator Agent:\n",
            "  --beam-size BEAM_SIZE\n",
            "        Beam size, if 1 then greedy search (default: 1)\n",
            "  --beam-min-length BEAM_MIN_LENGTH\n",
            "        Minimum length of prediction to be generated by the beam search\n",
            "        (default: 1)\n",
            "  --beam-context-block-ngram BEAM_CONTEXT_BLOCK_NGRAM\n",
            "        Size n-grams to block in beam search from the context. val <= 0\n",
            "        implies no blocking (default: -1)\n",
            "  --beam-block-ngram BEAM_BLOCK_NGRAM\n",
            "        Size n-grams to block in beam search. val <= 0 implies no blocking\n",
            "        (default: -1)\n",
            "  --beam-block-full-context BEAM_BLOCK_FULL_CONTEXT\n",
            "        Block n-grams from the *full* history context. Specify False to block\n",
            "        up to m tokens in the past, where m is truncation parameter for agent\n",
            "        (default: True)\n",
            "  --beam-length-penalty BEAM_LENGTH_PENALTY\n",
            "        Applies a length penalty. Set to 0 for no penalty. (default: 0.65)\n",
            "  --inference {delayedbeam,topk,nucleus,beam,greedy}\n",
            "        Generation algorithm (default: greedy)\n",
            "  --topk TOPK\n",
            "        K used in Top K sampling (default: 10)\n",
            "  --topp TOPP\n",
            "        p used in nucleus sampling (default: 0.9)\n",
            "  --beam-delay BEAM_DELAY\n",
            "        used in delayedbeam search (default: 30)\n",
            "  --beam-block-list-filename BEAM_BLOCK_LIST_FILENAME\n",
            "        Load a text file of hard blocks for beam search to never say.\n",
            "        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "        temperature to add during decoding (default: 1.0)\n",
            "  --compute-tokenized-bleu COMPUTE_TOKENIZED_BLEU\n",
            "        if true, compute tokenized bleu scores (default: False)\n",
            "\n",
            "TorchAgent Arguments:\n",
            "  -i, --interactive-mode INTERACTIVE_MODE\n",
            "        Whether in full interactive mode or not, which means generating text\n",
            "        or retrieving from a full set of candidates, which is necessary to\n",
            "        actually do full dialogue. However, during training or quick\n",
            "        validation (e.g. PPL for generation or ranking a few candidates for\n",
            "        ranking models) you might want these set to off. Typically, scripts\n",
            "        can set their preferred default behavior at the start, e.g. eval\n",
            "        scripts. (default: False)\n",
            "  -emb, --embedding-type {random,glove,glove-fixed,fasttext,fasttext-fixed,fasttext_cc,fasttext_cc-fixed}\n",
            "        Choose between different strategies for initializing word embeddings.\n",
            "        Default is random, but can also preinitialize from Glove or Fasttext.\n",
            "        Preinitialized embeddings can also be fixed so they are not updated\n",
            "        during training. (default: random)\n",
            "  -embp, --embedding-projection EMBEDDING_PROJECTION\n",
            "        If pretrained embeddings have a different dimensionality than your\n",
            "        embedding size, strategy for projecting to the correct size. If the\n",
            "        dimensions are the same, this is ignored unless you append \"-force\" to\n",
            "        your choice. (default: random)\n",
            "  --fp16 FP16\n",
            "        Use fp16 computations. (default: False)\n",
            "  --fp16-impl {safe,mem_efficient}\n",
            "        Implementation of FP16 to use (default: safe)\n",
            "  -rc, --rank-candidates RANK_CANDIDATES\n",
            "        Whether the model should parse candidates for ranking. (default:\n",
            "        False)\n",
            "  -tr, --truncate TRUNCATE\n",
            "        Truncate input lengths to increase speed / use less memory. (default:\n",
            "        -1)\n",
            "  --text-truncate TEXT_TRUNCATE\n",
            "        Text input truncation length: if not specified, this will default to\n",
            "        `truncate` (default: None)\n",
            "  --label-truncate LABEL_TRUNCATE\n",
            "        Label truncation length: if not specified, this will default to\n",
            "        `truncate` (default: None)\n",
            "  --history-reversed HISTORY_REVERSED\n",
            "        Reverse the history (default: False)\n",
            "  -histsz, --history-size HISTORY_SIZE\n",
            "        Number of past dialog utterances to remember. (default: -1)\n",
            "  -pt, --person-tokens PERSON_TOKENS\n",
            "        add person tokens to history. adds __p1__ in front of input text and\n",
            "        __p2__ in front of past labels when available or past utterances\n",
            "        generated by the model. these are added to the dictionary during\n",
            "        initialization. (default: False)\n",
            "  --split-lines SPLIT_LINES\n",
            "        split the dialogue history on newlines and save in separate vectors\n",
            "        (default: False)\n",
            "  --delimiter DELIMITER\n",
            "        Join history lines with this token, defaults to newline (default: )\n",
            "  --special-tok-lst SPECIAL_TOK_LST\n",
            "        Comma separated list of special tokens. In case of ambiguous parses\n",
            "        from special tokens, the ordering provided in this arg sets\n",
            "        precedence. (default: None)\n",
            "  -gpu, --gpu GPU\n",
            "        which GPU to use (default: -1)\n",
            "  --no-cuda\n",
            "        disable GPUs even if available. otherwise, will use GPUs if available\n",
            "        on the device.\n",
            "\n",
            "Optimizer Arguments:\n",
            "  -opt, --optimizer OPTIMIZER\n",
            "        Optimizer choice. Possible values: adadelta, adagrad, adam, adamw,\n",
            "        sparseadam, adamax, asgd, sgd, radam, rprop, rmsprop, optimizer,\n",
            "        nadam, lbfgs, mem_eff_adam, adafactor. (default: sgd)\n",
            "  -lr, --learningrate LEARNINGRATE\n",
            "        Learning rate (default: 1)\n",
            "  -clip, --gradient-clip GRADIENT_CLIP\n",
            "        gradient clipping using l2 norm (default: 0.1)\n",
            "  --adafactor-eps ADAFACTOR_EPS\n",
            "        Epsilon values for adafactor optimizer: regularization constants for\n",
            "        square gradient and parameter scale respectively (default: 1e-30,1e-3)\n",
            "  -mom, --momentum MOMENTUM\n",
            "        if applicable, momentum value for optimizer. (default: 0)\n",
            "  --nesterov NESTEROV\n",
            "        if applicable, whether to use nesterov momentum. (default: True)\n",
            "  -nu, --nus NUS\n",
            "        if applicable, nu value(s) for optimizer. can use a single value like\n",
            "        0.7 or a comma-separated tuple like 0.7,1.0 (default: 0.7)\n",
            "  -beta, --betas BETAS\n",
            "        if applicable, beta value(s) for optimizer. can use a single value\n",
            "        like 0.9 or a comma-separated tuple like 0.9,0.999 (default:\n",
            "        0.9,0.999)\n",
            "  -wdecay, --weight-decay WEIGHT_DECAY\n",
            "        Weight decay on the weights. (default: None)\n",
            "\n",
            "BPEHelper Arguments:\n",
            "  --bpe-vocab BPE_VOCAB\n",
            "        path to pre-trained tokenizer vocab (default: None)\n",
            "  --bpe-merge BPE_MERGE\n",
            "        path to pre-trained tokenizer merge (default: None)\n",
            "  --bpe-dropout BPE_DROPOUT\n",
            "        Use BPE dropout during training. (default: None)\n",
            "\n",
            "Learning Rate Scheduler:\n",
            "  --lr-scheduler {reduceonplateau,none,fixed,invsqrt,cosine,linear}\n",
            "        Learning rate scheduler. (default: reduceonplateau)\n",
            "  --lr-scheduler-patience LR_SCHEDULER_PATIENCE\n",
            "        LR scheduler patience. In number of validation runs. If using fixed\n",
            "        scheduler, LR is decayed every <patience> validations. (default: 3)\n",
            "  --lr-scheduler-decay LR_SCHEDULER_DECAY\n",
            "        Decay factor for LR scheduler, or how much LR is multiplied by when it\n",
            "        is lowered. (default: 0.5)\n",
            "  --invsqrt-lr-decay-gamma INVSQRT_LR_DECAY_GAMMA\n",
            "        Constant used only to find the lr multiplier for the invsqrt\n",
            "        scheduler. Must be set for --lr-scheduler invsqrt (default: -1)\n",
            "\n",
            "T5 Args:\n",
            "  --t5-model-arch {t5-small,t5-base,t5-large,t5-3b,t5-11b}\n",
            "  --t5-model-parallel T5_MODEL_PARALLEL\n",
            "        use HF model parallel (default: False)\n",
            "  --t5-dropout T5_DROPOUT\n",
            "        Dropout for T5 (default: 0.0)\n",
            "  --t5-generation-config {summarization,translation_en_to_de,translation_en_to_fr,translation_en_to_ro}\n",
            "        Task specific generation config for T5 (default: None)\n",
            "\n",
            "Search Query FiD Params:\n",
            "  --search-query-generator-model-file SEARCH_QUERY_GENERATOR_MODEL_FILE\n",
            "        Path to a query generator model. (default: None)\n",
            "  --search-query-generator-inference SEARCH_QUERY_GENERATOR_INFERENCE\n",
            "        Generation algorithm for the search query generator model (default:\n",
            "        greedy)\n",
            "  --search-query-generator-beam-min-length SEARCH_QUERY_GENERATOR_BEAM_MIN_LENGTH\n",
            "        The beam_min_length opt for the search query generator model (default:\n",
            "        1)\n",
            "  --search-query-generator-beam-size SEARCH_QUERY_GENERATOR_BEAM_SIZE\n",
            "        The beam_size opt for the search query generator model (default: 1)\n",
            "  --search-query-generator-text-truncate SEARCH_QUERY_GENERATOR_TEXT_TRUNCATE\n",
            "        Truncates the input to the search query generator model (default: 512)\n",
            "  --splitted-chunk-length SPLITTED_CHUNK_LENGTH\n",
            "        The number of tokens in each document split (default: 256)\n",
            "  --doc-chunk-split-mode {word,token}\n",
            "        split the docs by white space (word) or dict tokens. (default: word)\n",
            "  --n-ranked-doc-chunks N_RANKED_DOC_CHUNKS\n",
            "        Number of document chunks to keep if documents is too long and has to\n",
            "        be splitted. (default: 1)\n",
            "  --doc-chunks-ranker {tfidf,head}\n",
            "        How to rank doc chunks. (default: head)\n",
            "\n",
            "Search Engine FiD Params:\n",
            "  --search-server SEARCH_SERVER\n",
            "        A search server address. (default: None)\n",
            "\n",
            "BlenderBot2 Args:\n",
            "  --knowledge-access-method {classify,memory_only,search_only,all,none}\n",
            "        How to access knowledge for BlenderBot2 classify => classify the input\n",
            "        text, determine which knowledge to access memory_only => only access\n",
            "        memories search_only => only access search all => for each input,\n",
            "        access from memories and search none => do not access any knowledge.\n",
            "        (default: classify)\n",
            "  --memory-key MEMORY_KEY\n",
            "        Field in the observation from which to read memories. (default:\n",
            "        full_text)\n",
            "  --query-generator-key QUERY_GENERATOR_KEY\n",
            "        Field for input to the knowledge access classifier. (default:\n",
            "        full_text)\n",
            "  --gold-document-key GOLD_DOCUMENT_KEY\n",
            "        Field for selected docs. (default: __selected-docs__)\n",
            "  --gold-sentence-key GOLD_SENTENCE_KEY\n",
            "        Field for selected sentences (default: __selected-sentences__)\n",
            "  --gold-document-titles-key GOLD_DOCUMENT_TITLES_KEY\n",
            "        Field for selected docs titles. (default: __select-docs-titles__)\n",
            "  --insert-gold-docs INSERT_GOLD_DOCS\n",
            "        Set true to insert gold docs into retrieved docs. (default: False)\n",
            "  --memory-extractor-phrase MEMORY_EXTRACTOR_PHRASE\n",
            "        phrase used to extract memories from `--memory-key` in the\n",
            "        observation. For example, set to 'your persona:' to limit memories to\n",
            "        only lines that contain 'your persona:' (default: persona:)\n",
            "  --retriever-ignore-phrase RETRIEVER_IGNORE_PHRASE\n",
            "        filter input to the global knowledge retriever such that any utterance\n",
            "        containing the phrase will not be given as input. (default: persona:)\n",
            "  --memory-retriever-truncate MEMORY_RETRIEVER_TRUNCATE\n",
            "        Specify >0 for truncation to the memory retriever. (default: -1)\n",
            "  --retriever-delimiter RETRIEVER_DELIMITER\n",
            "        delimiter for the retriever (default: )\n",
            "  --share-search-and-memory-query-encoder SHARE_SEARCH_AND_MEMORY_QUERY_ENCODER\n",
            "        if true, query encoder is shared between search and memory retrievers.\n",
            "        (default: False)\n",
            "  --memory-reader-model {bert,bert_from_parlai_rag,dropout_poly}\n",
            "        Model for accessing the memory (default: None)\n",
            "  --memory-doc-title-delimiter MEMORY_DOC_TITLE_DELIMITER\n",
            "        title delimiter for memory docs (default: / )\n",
            "\n",
            "BlenderBot2 Query Generator Args:\n",
            "  --query-generator-ignore-phrase QUERY_GENERATOR_IGNORE_PHRASE\n",
            "        filter input to the query generator such that any utterance containing\n",
            "        the phrase will not be given as input. (default: persona:)\n",
            "  --query-generator-model-file QUERY_GENERATOR_MODEL_FILE\n",
            "        path to a query generator; specify if searching OR classifying inputs.\n",
            "        (default: zoo:blenderbot2/query_generator/model)\n",
            "  --query-generator-delimiter QUERY_GENERATOR_DELIMITER\n",
            "        delimiter for the query generator (default: )\n",
            "  --query-generator-inference QUERY_GENERATOR_INFERENCE\n",
            "        query generator inference type (default: beam)\n",
            "  --query-generator-beam-size QUERY_GENERATOR_BEAM_SIZE\n",
            "        SQ Gen Beam Size (default: 1)\n",
            "  --query-generator-beam-min-length QUERY_GENERATOR_BEAM_MIN_LENGTH\n",
            "        SQ Gen Beam Min Length (default: 2)\n",
            "  --query-generator-truncate QUERY_GENERATOR_TRUNCATE\n",
            "        Specify >0 for truncation to SQ generator (default: -1)\n",
            "\n",
            "BlenderBot2 Memory Decoder Args:\n",
            "  --memory-decoder-key MEMORY_DECODER_KEY\n",
            "        key of the observation for the memory decoder (default: full_text)\n",
            "  --memory-decoder-ignore-phrase MEMORY_DECODER_IGNORE_PHRASE\n",
            "        filter input to the memory decoder such that any utterance containing\n",
            "        the phrase will not be given as input. (default: persona:)\n",
            "  --memory-decoder-model-file MEMORY_DECODER_MODEL_FILE\n",
            "        path to a memory decoder. (default:\n",
            "        zoo:blenderbot2/memory_decoder/model)\n",
            "  --memory-decoder-delimiter MEMORY_DECODER_DELIMITER\n",
            "        delimiter for the memory decoder (default: )\n",
            "  --memory-decoder-beam-size MEMORY_DECODER_BEAM_SIZE\n",
            "        memory decoder Beam Size (default: 3)\n",
            "  --memory-decoder-beam-min-length MEMORY_DECODER_BEAM_MIN_LENGTH\n",
            "        memory decoder Beam Min Length (default: 10)\n",
            "  --memory-decoder-truncate MEMORY_DECODER_TRUNCATE\n",
            "        Specify >0 for truncation to memory decoder (default: -1)\n",
            "  --memory-decoder-one-line-memories MEMORY_DECODER_ONE_LINE_MEMORIES\n",
            "        specify to combine memories on one line, rather than several.\n",
            "        (default: False)\n",
            "\n",
            "Parse Error: argument --print-docs: expected one argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAb77yZ9fzMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e701b8-7e6a-4535-8b26-c175b6f91612"
      },
      "source": [
        "!python -m parlai interactive --model-file zoo:blenderbot2/blenderbot2_3B/model --search_server $HOST --outfile log.jsonl --save-format conversations --knowledge-access-method memory_only --debug "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n",
            "14:12:58 | \u001b[33mOverriding opt[\"model_file\"] to /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model (previously: zoo:blenderbot2/blenderbot2_3B/model)\u001b[0m\n",
            "14:12:58 | \u001b[33mOverriding opt[\"search_server\"] to 0.0.0.0:1111 (previously: None)\u001b[0m\n",
            "14:12:58 | \u001b[33mOverriding opt[\"knowledge_access_method\"] to memory_only (previously: classify)\u001b[0m\n",
            "14:12:58 | \u001b[33mOverriding opt[\"is_debug\"] to True (previously: False)\u001b[0m\n",
            "14:12:58 | loading dictionary from /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model.dict\n",
            "14:12:58 | num words = 8008\n",
            "14:12:58 | BlenderBot2Fid: full interactive mode on.\n",
            "14:13:48 | Creating the search engine retriever.\n",
            "14:13:48 | \u001b[33mNo protocol provided, using \"http://\"\u001b[0m\n",
            "14:13:51 | building data: /usr/local/lib/python3.7/dist-packages/data/models/hallucination/multiset_dpr/hf_bert_base.cp\n",
            "14:13:51 | Downloading https://dl.fbaipublicfiles.com/dpr/checkpoint/retriver/multiset/hf_bert_base.cp to /usr/local/lib/python3.7/dist-packages/data/models/hallucination/multiset_dpr/hf_bert_base.cp\n",
            "Downloading hf_bert_base.cp: 100% 876M/876M [00:28<00:00, 30.9MB/s]\n",
            "Downloading: 100% 420M/420M [00:09<00:00, 47.8MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "14:14:36 | building data: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/query_generator/model.tgz\n",
            "14:14:36 | Downloading http://parl.ai/downloads/_models/blenderbot2/query_generator/model.tgz to /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/query_generator/model.tgz\n",
            "Downloading model.tgz: 100% 750M/750M [00:20<00:00, 35.8MB/s]\n",
            "14:15:12 | Building Query Generator from file: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/query_generator/model\n",
            "Downloading vocab.bpe: 0.00B [00:00, ?B/s]\n",
            "Downloading encoder.json: 0.00B [00:00, ?B/s]\n",
            "14:15:22 | building data: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/memory_decoder/model.tgz\n",
            "14:15:22 | Downloading http://parl.ai/downloads/_models/blenderbot2/memory_decoder/model.tgz to /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/memory_decoder/model.tgz\n",
            "Downloading model.tgz: 100% 750M/750M [00:22<00:00, 32.8MB/s]\n",
            "14:15:59 | Building Memory Decoder from file: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/memory_decoder/model\n",
            "[downloading BART models: /usr/local/lib/python3.7/dist-packages/data/models/bart]\n",
            "Downloading bart.large.tar.gz: 100% 3.70G/3.70G [01:57<00:00, 31.4MB/s]\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x564fd0670000 @  0x7fa7144d5b6b 0x7fa7144f5379 0x7fa61208fcde 0x7fa612091452 0x7fa664b03749 0x7fa70d92cd59 0x564c57239045 0x564c571f9c52 0x564c5726cc25 0x564c57267ced 0x564c571fa7f3 0x564c571fa2f9 0x564c5734135d 0x564c572b0a0b 0x564c571f93a1 0x564c572eae1d 0x564c5726ce99 0x564c57267ced 0x564c57139e2b 0x564c57269fe4 0x564c572679ee 0x564c571fabda 0x564c57269737 0x564c571faafa 0x564c57268c0d 0x564c57267ced 0x564c571fabda 0x564c57268c0d 0x564c571faafa 0x564c57268c0d 0x564c571faafa\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x565032010000 @  0x7fa7144d5b6b 0x7fa7144f5379 0x7fa61208fcde 0x7fa612091452 0x7fa664b03749 0x7fa70d92cd59 0x564c57239045 0x564c571f9c52 0x564c5726cc25 0x564c57267ced 0x564c571fa7f3 0x564c571fa2f9 0x564c5734135d 0x564c572b0a0b 0x564c571f93a1 0x564c572eae1d 0x564c5726ce99 0x564c57267ced 0x564c57139e2b 0x564c57269fe4 0x564c572679ee 0x564c571fabda 0x564c57269737 0x564c571faafa 0x564c57268c0d 0x564c57267ced 0x564c571fabda 0x564c57268c0d 0x564c571faafa 0x564c57268c0d 0x564c571faafa\n",
            "{'id': 'Bart', 'episode_done': False, 'text': \"What's your favorite kind of ramen?\", 'beam_texts': [(\"What's your favorite kind of ramen?\", -0.00018543204350862652)], 'metrics': {'clen': AverageMetric(9), 'ctrunc': AverageMetric(0), 'ctrunclen': AverageMetric(0)}}\n",
            "14:21:14 | Total parameters: 3,022,943,744 (3,021,108,736 trainable)\n",
            "14:21:14 | Loading existing model params from /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model\n",
            "14:22:58 | Opt:\n",
            "14:22:58 |     activation: relu\n",
            "14:22:58 |     adafactor_eps: '[1e-30, 0.001]'\n",
            "14:22:58 |     adam_eps: 1e-08\n",
            "14:22:58 |     add_p1_after_newln: False\n",
            "14:22:58 |     allow_missing_init_opts: False\n",
            "14:22:58 |     attention_dropout: 0.0\n",
            "14:22:58 |     batchsize: 16\n",
            "14:22:58 |     beam_block_full_context: False\n",
            "14:22:58 |     beam_block_list_filename: None\n",
            "14:22:58 |     beam_block_ngram: 3\n",
            "14:22:58 |     beam_context_block_ngram: 3\n",
            "14:22:58 |     beam_delay: 30\n",
            "14:22:58 |     beam_length_penalty: 0.65\n",
            "14:22:58 |     beam_min_length: 20\n",
            "14:22:58 |     beam_size: 10\n",
            "14:22:58 |     betas: '[0.9, 0.999]'\n",
            "14:22:58 |     bpe_add_prefix_space: None\n",
            "14:22:58 |     bpe_debug: False\n",
            "14:22:58 |     bpe_dropout: None\n",
            "14:22:58 |     bpe_merge: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model.dict-merges.txt\n",
            "14:22:58 |     bpe_vocab: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model.dict-vocab.json\n",
            "14:22:58 |     candidates: inline\n",
            "14:22:58 |     cap_num_predictions: 100\n",
            "14:22:58 |     checkpoint_activations: False\n",
            "14:22:58 |     codes_attention_num_heads: 4\n",
            "14:22:58 |     codes_attention_type: basic\n",
            "14:22:58 |     compressed_indexer_factory: IVF4096_HNSW128,PQ128\n",
            "14:22:58 |     compressed_indexer_gpu_train: False\n",
            "14:22:58 |     compressed_indexer_nprobe: 64\n",
            "14:22:58 |     compute_tokenized_bleu: False\n",
            "14:22:58 |     converting: False\n",
            "14:22:58 |     data_parallel: False\n",
            "14:22:58 |     datapath: /usr/local/lib/python3.7/dist-packages/data\n",
            "14:22:58 |     datatype: train:stream\n",
            "14:22:58 |     delimiter: '  '\n",
            "14:22:58 |     dict_class: parlai.core.dict:DictionaryAgent\n",
            "14:22:58 |     dict_endtoken: __end__\n",
            "14:22:58 |     dict_file: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model.dict\n",
            "14:22:58 |     dict_initpath: None\n",
            "14:22:58 |     dict_language: english\n",
            "14:22:58 |     dict_loaded: True\n",
            "14:22:58 |     dict_lower: False\n",
            "14:22:58 |     dict_max_ngram_size: -1\n",
            "14:22:58 |     dict_maxtokens: -1\n",
            "14:22:58 |     dict_minfreq: 0\n",
            "14:22:58 |     dict_nulltoken: __null__\n",
            "14:22:58 |     dict_starttoken: __start__\n",
            "14:22:58 |     dict_textfields: text,labels\n",
            "14:22:58 |     dict_tokenizer: bytelevelbpe\n",
            "14:22:58 |     dict_unktoken: __unk__\n",
            "14:22:58 |     display_add_fields: \n",
            "14:22:58 |     display_examples: False\n",
            "14:22:58 |     display_prettify: False\n",
            "14:22:58 |     doc_chunk_split_mode: word\n",
            "14:22:58 |     doc_chunks_ranker: head\n",
            "14:22:58 |     download_path: None\n",
            "14:22:58 |     dpr_model_file: zoo:hallucination/bart_rag_token/model\n",
            "14:22:58 |     dpr_num_docs: 25\n",
            "14:22:58 |     dropout: 0.0\n",
            "14:22:58 |     dynamic_batching: None\n",
            "14:22:58 |     embedding_projection: random\n",
            "14:22:58 |     embedding_size: 2560\n",
            "14:22:58 |     embedding_type: random\n",
            "14:22:58 |     embeddings_scale: True\n",
            "14:22:58 |     encode_candidate_vecs: True\n",
            "14:22:58 |     encode_candidate_vecs_batchsize: 256\n",
            "14:22:58 |     eval_candidates: inline\n",
            "14:22:58 |     ffn_size: 10240\n",
            "14:22:58 |     fixed_candidate_vecs: reuse\n",
            "14:22:58 |     fixed_candidates_path: None\n",
            "14:22:58 |     force_fp16_tokens: True\n",
            "14:22:58 |     fp16: True\n",
            "14:22:58 |     fp16_impl: mem_efficient\n",
            "14:22:58 |     generation_model: transformer/generator\n",
            "14:22:58 |     gold_document_key: __selected-docs__\n",
            "14:22:58 |     gold_document_titles_key: select-docs-titles\n",
            "14:22:58 |     gold_knowledge_passage_key: checked_sentence\n",
            "14:22:58 |     gold_knowledge_title_key: title\n",
            "14:22:58 |     gold_sentence_key: __selected-sentences__\n",
            "14:22:58 |     gpu: -1\n",
            "14:22:58 |     gradient_clip: 0.1\n",
            "14:22:58 |     hide_labels: False\n",
            "14:22:58 |     history_add_global_end_token: end\n",
            "14:22:58 |     history_reversed: False\n",
            "14:22:58 |     history_size: -1\n",
            "14:22:58 |     hnsw_ef_construction: 200\n",
            "14:22:58 |     hnsw_ef_search: 128\n",
            "14:22:58 |     hnsw_indexer_store_n: 128\n",
            "14:22:58 |     ignore_bad_candidates: False\n",
            "14:22:58 |     image_cropsize: 224\n",
            "14:22:58 |     image_mode: raw\n",
            "14:22:58 |     image_size: 256\n",
            "14:22:58 |     indexer_buffer_size: 65536\n",
            "14:22:58 |     indexer_type: compressed\n",
            "14:22:58 |     inference: beam\n",
            "14:22:58 |     init_fairseq_model: None\n",
            "14:22:58 |     init_model: /private/home/kshuster/ParlAI/data/models/blender/blender_3B/model\n",
            "14:22:58 |     init_opt: None\n",
            "14:22:58 |     insert_gold_docs: True\n",
            "14:22:58 |     interactive_candidates: fixed\n",
            "14:22:58 |     interactive_mode: True\n",
            "14:22:58 |     interactive_task: True\n",
            "14:22:58 |     invsqrt_lr_decay_gamma: -1\n",
            "14:22:58 |     is_debug: True\n",
            "14:22:58 |     knowledge_access_method: memory_only\n",
            "14:22:58 |     label_truncate: 128\n",
            "14:22:58 |     learn_embeddings: True\n",
            "14:22:58 |     learn_positional_embeddings: False\n",
            "14:22:58 |     learningrate: 1e-05\n",
            "14:22:58 |     local_human_candidates_file: None\n",
            "14:22:58 |     log_keep_fields: all\n",
            "14:22:58 |     loglevel: info\n",
            "14:22:58 |     lr_scheduler: reduceonplateau\n",
            "14:22:58 |     lr_scheduler_decay: 0.5\n",
            "14:22:58 |     lr_scheduler_patience: 3\n",
            "14:22:58 |     max_doc_token_length: 64\n",
            "14:22:58 |     memory_attention: sqrt\n",
            "14:22:58 |     memory_decoder_beam_min_length: 10\n",
            "14:22:58 |     memory_decoder_beam_size: 3\n",
            "14:22:58 |     memory_decoder_delimiter: '\\n'\n",
            "14:22:58 |     memory_decoder_ignore_phrase: persona:\n",
            "14:22:58 |     memory_decoder_key: full_text\n",
            "14:22:58 |     memory_decoder_model_file: zoo:blenderbot2/memory_decoder/model\n",
            "14:22:58 |     memory_decoder_one_line_memories: False\n",
            "14:22:58 |     memory_decoder_truncate: -1\n",
            "14:22:58 |     memory_doc_delimiter: :\n",
            "14:22:58 |     memory_doc_title_delimiter: ' / '\n",
            "14:22:58 |     memory_extractor_phrase: persona:\n",
            "14:22:58 |     memory_key: personas\n",
            "14:22:58 |     memory_reader_model: None\n",
            "14:22:58 |     memory_retriever_truncate: -1\n",
            "14:22:58 |     memory_writer_model: bert\n",
            "14:22:58 |     memory_writer_model_file: zoo:hallucination/multiset_dpr/hf_bert_base.cp\n",
            "14:22:58 |     min_doc_token_length: 64\n",
            "14:22:58 |     model: projects.blenderbot2.agents.blenderbot2:BlenderBot2FidAgent\n",
            "14:22:58 |     model_file: /usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model\n",
            "14:22:58 |     model_parallel: True\n",
            "14:22:58 |     momentum: 0\n",
            "14:22:58 |     multitask_weights: '[3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]'\n",
            "14:22:58 |     n_decoder_layers: 24\n",
            "14:22:58 |     n_docs: 5\n",
            "14:22:58 |     n_encoder_layers: 2\n",
            "14:22:58 |     n_extra_positions: 0\n",
            "14:22:58 |     n_heads: 32\n",
            "14:22:58 |     n_layers: 2\n",
            "14:22:58 |     n_positions: 128\n",
            "14:22:58 |     n_ranked_doc_chunks: 1\n",
            "14:22:58 |     n_segments: 0\n",
            "14:22:58 |     nesterov: True\n",
            "14:22:58 |     no_cuda: False\n",
            "14:22:58 |     normalize_sent_emb: False\n",
            "14:22:58 |     nus: [0.7]\n",
            "14:22:58 |     optimizer: mem_eff_adam\n",
            "14:22:58 |     outfile: log.jsonl\n",
            "14:22:58 |     output_conversion_path: None\n",
            "14:22:58 |     output_scaling: 1.0\n",
            "14:22:58 |     override: \"{'model_file': '/usr/local/lib/python3.7/dist-packages/data/models/blenderbot2/blenderbot2_3B/model', 'search_server': '0.0.0.0:1111', 'outfile': 'log.jsonl', 'save_format': 'conversations', 'knowledge_access_method': 'memory_only', 'is_debug': True}\"\n",
            "14:22:58 |     parlai_home: /private/home/kshuster/ParlAI\n",
            "14:22:58 |     path_to_dense_embeddings: None\n",
            "14:22:58 |     path_to_dpr_passages: zoo:hallucination/wiki_passages/psgs_w100.tsv\n",
            "14:22:58 |     path_to_index: zoo:hallucination/wiki_index_compressed/compressed_pq\n",
            "14:22:58 |     person_tokens: False\n",
            "14:22:58 |     poly_attention_num_heads: 4\n",
            "14:22:58 |     poly_attention_type: basic\n",
            "14:22:58 |     poly_faiss_model_file: None\n",
            "14:22:58 |     poly_n_codes: 64\n",
            "14:22:58 |     poly_score_initial_lambda: 0.5\n",
            "14:22:58 |     polyencoder_init_model: wikito\n",
            "14:22:58 |     polyencoder_type: codes\n",
            "14:22:58 |     print_docs: False\n",
            "14:22:58 |     query_generator_beam_min_length: 2\n",
            "14:22:58 |     query_generator_beam_size: 1\n",
            "14:22:58 |     query_generator_delimiter: '\\n'\n",
            "14:22:58 |     query_generator_ignore_phrase: persona:\n",
            "14:22:58 |     query_generator_inference: beam\n",
            "14:22:58 |     query_generator_key: full_text\n",
            "14:22:58 |     query_generator_model_file: zoo:blenderbot2/query_generator/model\n",
            "14:22:58 |     query_generator_truncate: -1\n",
            "14:22:58 |     query_model: bert_from_parlai_rag\n",
            "14:22:58 |     rag_model_type: token\n",
            "14:22:58 |     rag_query_truncate: 512\n",
            "14:22:58 |     rag_retriever_query: full_history\n",
            "14:22:58 |     rag_retriever_type: search_engine\n",
            "14:22:58 |     rag_turn_discount_factor: 1.0\n",
            "14:22:58 |     rag_turn_marginalize: doc_then_turn\n",
            "14:22:58 |     rag_turn_n_turns: 2\n",
            "14:22:58 |     rank_candidates: False\n",
            "14:22:58 |     rank_top_k: -1\n",
            "14:22:58 |     reduction_type: mean\n",
            "14:22:58 |     regret: False\n",
            "14:22:58 |     regret_dict_file: None\n",
            "14:22:58 |     regret_intermediate_maxlen: 32\n",
            "14:22:58 |     regret_model_file: None\n",
            "14:22:58 |     regret_override_index: False\n",
            "14:22:58 |     relu_dropout: 0.0\n",
            "14:22:58 |     repeat_blocking_heuristic: True\n",
            "14:22:58 |     retriever_debug_index: None\n",
            "14:22:58 |     retriever_delimiter: '\\n'\n",
            "14:22:58 |     retriever_embedding_size: 768\n",
            "14:22:58 |     retriever_ignore_phrase: persona:\n",
            "14:22:58 |     return_cand_scores: False\n",
            "14:22:58 |     save_format: conversations\n",
            "14:22:58 |     search_query_generator_beam_min_length: 2\n",
            "14:22:58 |     search_query_generator_beam_size: 1\n",
            "14:22:58 |     search_query_generator_inference: greedy\n",
            "14:22:58 |     search_query_generator_model_file: zoo:blenderbot2/query_generator/model\n",
            "14:22:58 |     search_query_generator_text_truncate: 512\n",
            "14:22:58 |     search_server: 0.0.0.0:1111\n",
            "14:22:58 |     share_encoders: True\n",
            "14:22:58 |     share_search_and_memory_query_encoder: False\n",
            "14:22:58 |     share_word_embeddings: True\n",
            "14:22:58 |     single_turn: False\n",
            "14:22:58 |     skip_generation: False\n",
            "14:22:58 |     skip_retrieval_token: no_passages_used\n",
            "14:22:58 |     special_tok_lst: None\n",
            "14:22:58 |     split_lines: False\n",
            "14:22:58 |     splitted_chunk_length: 256\n",
            "14:22:58 |     starttime: Jul09_14-08\n",
            "14:22:58 |     t5_dropout: 0.0\n",
            "14:22:58 |     t5_generation_config: None\n",
            "14:22:58 |     t5_model_arch: t5-base\n",
            "14:22:58 |     t5_model_parallel: False\n",
            "14:22:58 |     task: None\n",
            "14:22:58 |     temperature: 1.0\n",
            "14:22:58 |     text_truncate: 128\n",
            "14:22:58 |     tfidf_max_doc_paragraphs: -1\n",
            "14:22:58 |     tfidf_model_path: zoo:wikipedia_full/tfidf_retriever/model\n",
            "14:22:58 |     thorough: False\n",
            "14:22:58 |     topk: 10\n",
            "14:22:58 |     topp: 0.9\n",
            "14:22:58 |     train_predict: False\n",
            "14:22:58 |     truncate: 128\n",
            "14:22:58 |     update_freq: 1\n",
            "14:22:58 |     use_memories: False\n",
            "14:22:58 |     use_reply: label\n",
            "14:22:58 |     variant: prelayernorm\n",
            "14:22:58 |     verbose: False\n",
            "14:22:58 |     warmup_rate: 0.0001\n",
            "14:22:58 |     warmup_updates: 100\n",
            "14:22:58 |     weight_decay: None\n",
            "14:22:58 |     wrap_memory_encoder: False\n",
            "\u001b[1;31mEnter [DONE] if you want to end the episode, [EXIT] to quit.\u001b[0;0m\n",
            "14:23:00 | creating task(s): interactive\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m hi\n",
            "/usr/local/lib/python3.7/dist-packages/parlai/core/torch_generator_agent.py:1610: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  hyp_ids = best_idxs // voc_size\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mHello, how are you? _POTENTIALLY_UNSAFE__\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m persona: You like basketball\\n What is your favourite sport?\n",
            "[DONE]\n",
            "{EXIT]\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI don't really have a favorite sport, but I do like to play basketball with my friends.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m \u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI don't know what that means. _POTENTIALLY_UNSAFE__\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Hi\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mIt means exit, as in the exit you take when you leave a place.  It's a good way to get out of a bad situation.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [DONE]\n",
            "CHAT DONE \n",
            "\n",
            "... preparing new chat... \n",
            "\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Which sport do you like?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI don't really have a favorite sport. I just like to watch sports. _POTENTIALLY_UNSAFE__\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m persona: your favourite game is Overwatch/n What is your favourite game?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI like to play Overwatch, but I'm not very good at it. What about you?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I like to play League of Legends. Do you know that game?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI've heard of it, but never played it. How long have you been playing it for?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I have been playing for 8 years.\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mWow, that's a long time! Do you have any other hobbies besides playing video games?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m No\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mWhat do you like to do in your spare time? Do you play video games with your friends?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m persona: you are a woman\\n persona:you are 22 years old\\n persona: your name is Misato\\n persona:you are japanese\\n Where are you from?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI am from the united states. What about you? What is your favorite color? Mine is blue.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m What is your nationality?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mMy nationality is american. Do you speak any other languages besides english? I speak spanish and french.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I speak Turki\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mI have never heard of that language. What is it like to speak it? Is it difficult?\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Yes it is very difficult\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mHow long have you been speaking turki? I would love to learn a new language one day.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m It is my native language\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mDo you have any tips for learning turkish? I'd love to be able to speak another language.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m You can start by reading short Turkish news. Do you want to learn some words from Turkish?\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mThat's a good idea. I'd like to learn how to say hello and goodbye.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m Hello in Turkish is Merhaba. Goodbye in Turkish is Görüşürüz. \n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mDo you speak any other languages? I'm fluent in french and english. I also speak spanish.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m I am fluent in Japanese\n",
            "\u001b[0;34m[BlenderBot2Fid]:\u001b[0;0m \u001b[1mHow long have you been learning japanese? I would love to visit japan someday.\u001b[0;0m\n",
            "\u001b[0mEnter Your Message:\u001b[0;0m [EXIT]\n",
            "CHAT DONE \n",
            "16:44:00 | Saving log to log.jsonl in Conversations format\n",
            "16:44:00 | Conversations saved to file: log.jsonl\n",
            "16:44:00 | Writing metadata to file log.metadata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PnXfDWF572u9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}